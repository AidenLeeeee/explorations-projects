{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "edb30d6d",
   "metadata": {},
   "source": [
    "# 1. Source Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c5cae2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "f9b6ec21",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "데이터 크기: 187088\n",
      "Examples:\n",
      " [\"Now I've heard there was a secret chord\", 'That David played, and it pleased the Lord', \"But you don't really care for music, do you?\"]\n"
     ]
    }
   ],
   "source": [
    "# Text 파일의 경로를 지정\n",
    "txt_file_path = os.getenv('HOME')+'/aiffel/lyricist/data/lyrics/*'\n",
    "\n",
    "txt_list = glob.glob(txt_file_path)\n",
    "\n",
    "raw_corpus = []\n",
    "\n",
    "# 여러개의 txt 파일을 모두 읽어서 raw_corpus 에 저장\n",
    "for txt_file in txt_list:\n",
    "    with open(txt_file, \"r\") as f:\n",
    "        raw = f.read().splitlines()\n",
    "        raw_corpus.extend(raw)\n",
    "\n",
    "# Test\n",
    "print(\"데이터 크기:\", len(raw_corpus))\n",
    "print(\"Examples:\\n\", raw_corpus[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dec90705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문장을 정제하는 함수를 선언\n",
    "def preprocess_sentence(sentence):\n",
    "    # 소문자로 변경 후, 양 쪽의 공백을 제거\n",
    "    sentence = sentence.lower().strip()\n",
    "    # 명시된 특수문자의 양쪽에 공백을 추가\n",
    "    sentence = re.sub(r\"([?.!,¿])\", r\" \\1 \", sentence)\n",
    "    # 두 개 이상의 공백을 하나의 공백으로 변경\n",
    "    sentence = re.sub(r'[\" \"]+', \" \", sentence)\n",
    "    # 명시된 문자가 아닐 경우, 공백으로 변경\n",
    "    sentence = re.sub(r\"[^a-zA-Z?.!,¿]+\", \" \", sentence)\n",
    "    # 양 쪽의 공백을 제거\n",
    "    sentence = sentence.strip()\n",
    "    # 양 끝에 '<start>', '<end>' 추가\n",
    "    sentence = '<start> ' + sentence + ' <end>'\n",
    "    \n",
    "    return sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5dd0eadd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156227\n"
     ]
    }
   ],
   "source": [
    "# corpus 에 길이가 1 ~ 15 인 문장을 정제하여 저장\n",
    "corpus = []\n",
    "\n",
    "for s in raw_corpus:\n",
    "    if len(s) == 0: \n",
    "        continue  \n",
    "    sentence = preprocess_sentence(s)\n",
    "    \n",
    "    if len(sentence.split()) > 15:\n",
    "        continue\n",
    "        \n",
    "    corpus.append(sentence)\n",
    "\n",
    "# Test\n",
    "print(len(corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "4ac32494",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(156227, 15)\n"
     ]
    }
   ],
   "source": [
    "# 각 문장을 tokenize 하여 12,000 개의 단어로 tokenizer 에 저장\n",
    "def tokenize(corpus):\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(\n",
    "        num_words=12000,\n",
    "        filters=' ',\n",
    "        oov_token=\"<unk>\"\n",
    "    )\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    \n",
    "    # tokenizer 를 활용하여 corpus 를 tensor 로 매핑\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    # tensor 의 시퀀스 길이를 동일하게 맞춤 (문장의 끝에 pad(0) 를 추가)\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')  \n",
    "\n",
    "    return tensor, tokenizer\n",
    "\n",
    "tensor, tokenizer = tokenize(corpus)\n",
    "\n",
    "# Test\n",
    "print(tensor.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "11bc195a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   2,   50,    4,   95,  303,   62,   53,    9,  946, 6269],\n",
       "       [   2,   15, 2971,  872,    5,    8,   11, 5747,    6,  374],\n",
       "       [   2,   33,    7,   40,   16,  164,  288,   28,  333,    5],\n",
       "       [   2,   11,  336,   23,   41,    3,    0,    0,    0,    0],\n",
       "       [   2,    6, 4490,    5,    6, 2040,    3,    0,    0,    0]],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test\n",
    "# 문장의 시작은 2, 문장의 끝은 3, 길이가 부족할 경우 pad(0)\n",
    "tensor[:5, :10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6bb54ddf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(156227, 14)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# source_input, target_input 선언\n",
    "# src_input 은 주로 pad(0) 가 삭제\n",
    "src_input = tensor[:, :-1]\n",
    "# tgt_input 은 '<start>'(2) 가 삭제\n",
    "tgt_input = tensor[:, 1:]\n",
    "\n",
    "# Test\n",
    "src_input.shape\n",
    "tgt_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "048f2815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train, val dataset 으로 split\n",
    "enc_train, enc_val, dec_train, dec_val = train_test_split(src_input,\n",
    "                                                          tgt_input,\n",
    "                                                          test_size=0.2,\n",
    "                                                          random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "304f5406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(124981, 14)\n",
      "(31246, 14)\n",
      "(124981, 14)\n",
      "(31246, 14)\n"
     ]
    }
   ],
   "source": [
    "# Test\n",
    "print(enc_train.shape)\n",
    "print(enc_val.shape)\n",
    "print(dec_train.shape)\n",
    "print(dec_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8d5e946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 14), (None, 14)), types: (tf.int32, tf.int32)>\n",
      "489\n"
     ]
    }
   ],
   "source": [
    "# Train Dataset Object\n",
    "BUFFER_SIZE = len(enc_train)\n",
    "BATCH_SIZE = 256\n",
    "steps_per_epoch = len(enc_train) // BATCH_SIZE\n",
    "# pad(0) 을 포함하여 단어장의 길이는 12,001\n",
    "VOCAB_SIZE = tokenizer.num_words + 1\n",
    "\n",
    "# Train Dataset 생성 (enc_train, dec_train)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((enc_train, dec_train))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE)\n",
    "# data 를 최대한 확보하기 위해 drop_remainder=False\n",
    "train_dataset = train_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "# Test\n",
    "print(train_dataset)\n",
    "print(len(train_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1cdd5216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 14), (None, 14)), types: (tf.int32, tf.int32)>\n",
      "123\n"
     ]
    }
   ],
   "source": [
    "# Validation Dataset Object\n",
    "BUFFER_SIZE = len(enc_val)\n",
    "steps_per_epoch = len(enc_val) // BATCH_SIZE\n",
    "\n",
    "# Validation Dataset 생성 (enc_val, dec_val)\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((enc_val, dec_val))\n",
    "val_dataset = val_dataset.shuffle(BUFFER_SIZE)\n",
    "# data 를 최대한 확보하기 위해 drop_remainder=False\n",
    "val_dataset = val_dataset.batch(BATCH_SIZE, drop_remainder=False)\n",
    "\n",
    "# Test\n",
    "print(val_dataset)\n",
    "print(len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f07068ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model 을 상속받는 TextGenerator Class 생성\n",
    "class TextGenerator(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_size, hidden_size):\n",
    "        super().__init__()\n",
    "        \n",
    "        # embedding, rnn_1, rnn_2, linear 4 layers\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_size)\n",
    "        self.rnn_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.rnn_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "        self.linear = tf.keras.layers.Dense(vocab_size)\n",
    "        \n",
    "    def call(self, x):\n",
    "        out = self.embedding(x)\n",
    "        out = self.rnn_1(out)\n",
    "        out = self.rnn_2(out)\n",
    "        out = self.linear(out)\n",
    "        \n",
    "        return out\n",
    "\n",
    "# word vector 의 차원 수\n",
    "embedding_size = 256\n",
    "# 일꾼 수\n",
    "hidden_size = 1800\n",
    "# model 에 TextGenerator 인스턴스 생성\n",
    "model = TextGenerator(tokenizer.num_words + 1, embedding_size , hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8e938c6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(256, 14, 12001), dtype=float32, numpy=\n",
       "array([[[-7.42763441e-05,  2.14289888e-04, -8.60783475e-05, ...,\n",
       "          3.93387774e-04, -6.47540655e-05, -7.08866792e-05],\n",
       "        [-1.21060148e-04,  4.88928810e-04, -1.81302501e-04, ...,\n",
       "          4.62958240e-04, -5.54173348e-05,  1.26629428e-04],\n",
       "        [-1.40922741e-04,  6.32188632e-04, -1.47154322e-04, ...,\n",
       "          3.58747173e-04,  7.91960701e-05,  2.40859910e-04],\n",
       "        ...,\n",
       "        [-1.16421969e-03, -5.55926934e-04, -2.62523972e-04, ...,\n",
       "          1.44930629e-04,  8.51180987e-04,  1.64432020e-03],\n",
       "        [-1.60559721e-03, -7.98600842e-04, -4.12732043e-04, ...,\n",
       "         -3.76050361e-04,  1.03018014e-03,  1.96206593e-03],\n",
       "        [-2.03839503e-03, -1.03370880e-03, -5.67074690e-04, ...,\n",
       "         -9.23107262e-04,  1.19664101e-03,  2.23791040e-03]],\n",
       "\n",
       "       [[-7.42763441e-05,  2.14289888e-04, -8.60783475e-05, ...,\n",
       "          3.93387774e-04, -6.47540655e-05, -7.08866792e-05],\n",
       "        [ 7.55212895e-05, -4.44176330e-05, -3.75324627e-04, ...,\n",
       "          4.93227330e-04,  1.36683040e-04, -5.86580427e-05],\n",
       "        [ 1.90921608e-04, -3.02220200e-04, -7.00005563e-04, ...,\n",
       "          2.54351180e-04,  3.54345713e-04, -2.13515406e-04],\n",
       "        ...,\n",
       "        [ 3.47732392e-04, -8.66105896e-04, -6.14405493e-04, ...,\n",
       "         -2.82128225e-04,  2.09919969e-03,  4.39293181e-05],\n",
       "        [ 1.62258031e-04, -8.25386203e-04, -4.91344661e-04, ...,\n",
       "         -2.85326765e-04,  2.05209036e-03,  4.20116819e-04],\n",
       "        [-2.39666188e-04, -8.63539462e-04, -4.06333944e-04, ...,\n",
       "         -4.02135163e-04,  2.03482667e-03,  8.64619797e-04]],\n",
       "\n",
       "       [[-7.42763441e-05,  2.14289888e-04, -8.60783475e-05, ...,\n",
       "          3.93387774e-04, -6.47540655e-05, -7.08866792e-05],\n",
       "        [ 1.92101201e-04,  3.14385019e-04, -2.25392345e-04, ...,\n",
       "          5.69955853e-04, -2.75670493e-04, -1.00016136e-04],\n",
       "        [ 3.35636578e-04,  3.23408283e-04, -2.29725891e-04, ...,\n",
       "          4.57916380e-04, -6.81670848e-04, -2.10095284e-04],\n",
       "        ...,\n",
       "        [-1.97537639e-03, -8.36819701e-04, -1.04030292e-03, ...,\n",
       "         -1.83221255e-03,  8.64775560e-04,  1.08573376e-03],\n",
       "        [-2.46879109e-03, -1.05765485e-03, -1.09986623e-03, ...,\n",
       "         -2.21045944e-03,  1.04134646e-03,  1.51713693e-03],\n",
       "        [-2.91327317e-03, -1.26930384e-03, -1.16295565e-03, ...,\n",
       "         -2.59301136e-03,  1.19965733e-03,  1.89650385e-03]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[-7.42763441e-05,  2.14289888e-04, -8.60783475e-05, ...,\n",
       "          3.93387774e-04, -6.47540655e-05, -7.08866792e-05],\n",
       "        [ 1.92101201e-04,  3.14385019e-04, -2.25392345e-04, ...,\n",
       "          5.69955853e-04, -2.75670493e-04, -1.00016136e-04],\n",
       "        [ 4.33480571e-04,  3.11737880e-04, -4.14734066e-04, ...,\n",
       "          8.46883224e-04, -2.53082020e-04, -3.31504765e-04],\n",
       "        ...,\n",
       "        [ 3.25997622e-04,  9.06454516e-05, -8.92241427e-04, ...,\n",
       "         -1.33127134e-04,  6.70429494e-04, -1.73017988e-03],\n",
       "        [ 2.80241857e-05, -3.16574515e-05, -8.86860653e-04, ...,\n",
       "         -2.40254565e-04,  6.58703153e-04, -1.47396105e-03],\n",
       "        [-4.70356783e-04, -2.36385255e-04, -8.76466627e-04, ...,\n",
       "         -4.19557589e-04,  7.11764675e-04, -1.03899301e-03]],\n",
       "\n",
       "       [[-7.42763441e-05,  2.14289888e-04, -8.60783475e-05, ...,\n",
       "          3.93387774e-04, -6.47540655e-05, -7.08866792e-05],\n",
       "        [-1.21060148e-04,  4.88928810e-04, -1.81302501e-04, ...,\n",
       "          4.62958240e-04, -5.54173348e-05,  1.26629428e-04],\n",
       "        [-2.42596492e-04,  8.03733943e-04, -4.83335985e-04, ...,\n",
       "          6.09294802e-04,  1.14649101e-05,  2.81907094e-04],\n",
       "        ...,\n",
       "        [ 1.93397165e-04,  7.94310879e-04, -8.95543722e-04, ...,\n",
       "         -2.96436687e-04, -8.25801253e-05,  3.26238776e-04],\n",
       "        [-4.10040229e-04,  3.64167645e-04, -7.85201730e-04, ...,\n",
       "         -5.65486087e-04,  1.15132330e-04,  6.66999666e-04],\n",
       "        [-1.03502418e-03, -5.30059260e-05, -7.29530468e-04, ...,\n",
       "         -9.12525633e-04,  3.48799018e-04,  1.02516066e-03]],\n",
       "\n",
       "       [[-7.42763441e-05,  2.14289888e-04, -8.60783475e-05, ...,\n",
       "          3.93387774e-04, -6.47540655e-05, -7.08866792e-05],\n",
       "        [-1.58466410e-05,  4.96936613e-04, -2.72375502e-04, ...,\n",
       "          2.78730615e-04,  1.02971542e-04, -6.45610853e-05],\n",
       "        [ 4.99460184e-05,  4.61113494e-04, -3.79914942e-04, ...,\n",
       "          2.39216228e-04,  1.24409649e-04, -3.44337204e-05],\n",
       "        ...,\n",
       "        [-5.69383672e-04, -3.33372998e-04, -4.14439535e-04, ...,\n",
       "         -9.81466612e-04,  6.67867367e-04,  9.27142042e-04],\n",
       "        [-1.16631354e-03, -6.72257156e-04, -4.68378217e-04, ...,\n",
       "         -1.31404202e-03,  7.60868017e-04,  1.33219291e-03],\n",
       "        [-1.72857579e-03, -9.81259393e-04, -5.49659133e-04, ...,\n",
       "         -1.68801937e-03,  8.74345598e-04,  1.70359050e-03]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 배치 하나를 가져와서 Test\n",
    "for src_sample, tgt_sample in train_dataset.take(1):\n",
    "    break\n",
    "    \n",
    "model(src_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "4ac3930e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"text_generator_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_5 (Embedding)      multiple                  3072256   \n",
      "_________________________________________________________________\n",
      "lstm_10 (LSTM)               multiple                  14810400  \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               multiple                  25927200  \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              multiple                  21613801  \n",
      "=================================================================\n",
      "Total params: 65,423,657\n",
      "Trainable params: 65,423,657\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Model.summary()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "364eff70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "489/489 [==============================] - 208s 420ms/step - loss: 3.4141 - val_loss: 2.9995\n",
      "Epoch 2/10\n",
      "489/489 [==============================] - 215s 439ms/step - loss: 2.8462 - val_loss: 2.7465\n",
      "Epoch 3/10\n",
      "489/489 [==============================] - 215s 440ms/step - loss: 2.5543 - val_loss: 2.5616\n",
      "Epoch 4/10\n",
      "489/489 [==============================] - 216s 441ms/step - loss: 2.2704 - val_loss: 2.4293\n",
      "Epoch 5/10\n",
      "489/489 [==============================] - 216s 441ms/step - loss: 2.0032 - val_loss: 2.3306\n",
      "Epoch 6/10\n",
      "489/489 [==============================] - 216s 442ms/step - loss: 1.7598 - val_loss: 2.2566\n",
      "Epoch 7/10\n",
      "489/489 [==============================] - 216s 442ms/step - loss: 1.5472 - val_loss: 2.2072\n",
      "Epoch 8/10\n",
      "489/489 [==============================] - 216s 442ms/step - loss: 1.3689 - val_loss: 2.1836\n",
      "Epoch 9/10\n",
      "489/489 [==============================] - 216s 442ms/step - loss: 1.2271 - val_loss: 2.1759\n",
      "Epoch 10/10\n",
      "489/489 [==============================] - 216s 442ms/step - loss: 1.1223 - val_loss: 2.1848\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fd13b373100>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# optimizer 선언\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "# loss algorithm 선언\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True,\n",
    "    reduction='none'\n",
    ")\n",
    "\n",
    "# compile\n",
    "model.compile(loss=loss, optimizer=optimizer)\n",
    "\n",
    "# fit (EPOCHS = 10)\n",
    "model.fit(train_dataset,\n",
    "          epochs=10,\n",
    "          validation_data=val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c915405",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 문장 생성 함수 정의\n",
    "def generate_text(model, tokenizer, init_sentence=\"<start>\", max_len=15):\n",
    "    # init_sentence 를 tensor 로 변환\n",
    "    test_input = tokenizer.texts_to_sequences([init_sentence])\n",
    "    test_tensor = tf.convert_to_tensor(test_input, dtype=tf.int64)\n",
    "    end_token = tokenizer.word_index[\"<end>\"]\n",
    "\n",
    "    while True:\n",
    "        # 입력받은 문장의 tensor 를 모델에 입력\n",
    "        predict = model(test_tensor) \n",
    "        \n",
    "        # 예측된 값 중 가장 높은 확률의 word index\n",
    "        predict_word = tf.argmax(tf.nn.softmax(predict, axis=-1), axis=-1)[:, -1] \n",
    "        \n",
    "        # 위에서 예측된 word index를 test_tensor 뒤에 추가\n",
    "        test_tensor = tf.concat([test_tensor, tf.expand_dims(predict_word, axis=0)], axis=-1)\n",
    "        \n",
    "        # 모델이 <end>를 예측했거나, max_len에 도달했다면 문장 생성을 종료하고 while 탈출\n",
    "        if predict_word.numpy()[0] == end_token: \n",
    "            break\n",
    "        if test_tensor.shape[1] >= max_len: \n",
    "            break\n",
    "\n",
    "    generated = \"\"\n",
    "    # tokenizer를 활용해 test_tensor 의 index 를 단어로 변환\n",
    "    # generated 에 저장\n",
    "    for word_index in test_tensor[0].numpy():\n",
    "        generated += tokenizer.index_word[word_index] + \" \"\n",
    "\n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f3ffc143",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<start> i love you , liberian girl , <end> '"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# enc_train 으로 학습한 model 의 문장 생성\n",
    "generate_text(model, tokenizer, init_sentence=\"<start> i love\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84577d44",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdf2974",
   "metadata": {},
   "source": [
    "# 2. Retrospection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2ac70f",
   "metadata": {},
   "source": [
    "<h2 style=\"font-style:italic\">2022.01.14 - [E-04]Lyricist Project</h2>\n",
    "\n",
    "> 이번 프로젝트에서는 팝송의 가사들로부터 학습한 RNN 모델을 활용하여 새로운 가사를 생성하는 Lyricist 를 구현해보았다. 아래에서는 프로젝트를 진행하면서 어려웠던 부분들이나, 알게된 점, 앞으로 학습해나가야할 모호한 점에 대해 회고해보도록 하겠다.\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb30ef9d",
   "metadata": {},
   "source": [
    "**(1)** **어려웠던 점**\n",
    "<br>\n",
    "<br>\n",
    "- 이번 프로젝트에서 가장 어려웠던 점은 적합한 파라미터값을 찾아내는 작업이었다. 이전까지 해왔던 프로젝트와는 달리, 데이터가 많아 학습에 오랜 시간이 걸린 탓에 최적의 파라미터를 찾아내는데 어려움을 겪었다. 다만, 과적합(overfitting)의 개념에 대해 학습한 이후로는 무작정 파라미터의 값을 증가시키는 무모한 실험을 시도하지는 않게 되었다.\n",
    "<br>\n",
    "<br>\n",
    "- 모델에서 세팅한 하이퍼 파라미터는 embedding_size 와 hidden_size 였다. 처음에는 embedding_size 를 256, hidden_size 를 1024 로 세팅하여 학습을 진행했다. 이 때, validation loss 는 2.5 에서 2.6 의 수치가 나왔다. 루브릭 성능 평가 기준은 2.2 이하였으므로, 하이퍼 파라미터를 변경하여야 했고 각 하이퍼 파라미터가 모델의 validation loss 에 어떠한 영향을 미치는지에 대해서 알아보기 위해 embedding_size 를 512, hidden_size 를 2048 로 다시 설정했다. 이 때, loss 는 2.2 보다 낮게 나와주는 듯 했으나, 결국 EPOCH 7 정도부터 증가하는 모습을 보여주었다. 물론, 충분한 EPOCH 를 돌리지 않아 확신할 수는 없었지만, 이를 과적합(overfitting) 으로 생각했다. 다음은 hidden_size 만을 감소시켜보았다. embedding_size 는 512, hidden_size 는 1024 로 실험하였다. loss 는 다시 2.3 ~ 2.4 로 증가하기 시작했고, hidden_size 를 1500 ~ 2000 사이로 fix 하기로 결정을 내렸다. 이후부터는 embedding_size 를 변경시키며 성능을 측정했고, embedding_size 는 생각보다 클 필요가 없다는 점을 깨달았다. 따라서, embedding_size 는 초기값 그대로 256 으로 설정하고, hidden_size 를 1800 으로 시험했다. 물론 마지막 EPOCH 에서는 loss 값이 잠깐 증가하는 양상을 보이나, epoch 10 에 loss 가 한 번 증가했다고 해서 과적합(overfitting) 으로 예상하기에는 무리라고 판단했다. 결국, 2.17 에서 2.18 사이의 2.2 이하 성능 지표값을 도출하였고 이러한 실험 과정에서 모델을 학습시키는 시간이 굉장히 오래걸렸다는 점이 이번 프로젝트에서의 난관이었다.\n",
    "<br>\n",
    "<br>\n",
    "- 정규표현식에 대한 부분도 쉽지 않았다. 사실 정규표현식이 웹크롤링이나 자동화같은 분야에서는 자주 쓰인다는 말을 들어본 적은 있었지만, 이전까지 내가 학습했던 분야들에서는 정규표현식이 필요하지 않았다. 하지만, 다양한 텍스트 파일의 문장에 대해 format 을 전처리해주어야 하는 이번 프로젝트에서 사실상 정규표현식은 모델의 성능에 영향을 미칠 수 있는 중요한 파트였다. 이번 프로젝트를 통해 각 정규표현식에서의 메타 문자와 문법에 대해 맛보았고, 그 중요성에 대해 알게 되었으니 앞으로 꾸준히 호기심을 가지고 학습해나갈 것이다.\n",
    "<br>\n",
    "<br>\n",
    "- RNN 의 원리도 굉장히 복잡하고 어려웠다. embedding layer 와 rnn layer 2개, linear(dense) 의 4 개의 layer 로 구성된 간단한 RNN 이었지만, LSTM 레이어에서 이루어지는 과정들에 대해서 감이 잘 잡히지 않았다. 지금까지 이해한 바로는, embedding layer 에서는 들어온 입력 데이터들의 단어들은 one-hot encoding 처럼 추상화되어 LSTM layer 로 전달된다. 즉, embedding_size 가 극단적으로 클 경우에는 각 단어가 지나치게 추상화되어 모델에 혼란을 줄 수 있게 되는 것이다. 이후, LSTM 층에서는 문장을 순차적으로 읽으며 단어 간 연관성을 분석하게 된다. 마지막으로 이러한 연관성을 기반으로 linear 층에서 다음에 올 단어들을 예측하여 생성하게 된다. 아직까지는 LSTM 에서 하는 역할에 대해 정확하게 설명하기 힘들지만, 앞으로 RNN 의 각 계층에 대해 학습해나가면서 모델을 적절하게 설계하고, 최적의 하이퍼 파라미터 값을 찾아내는 방법을 알아가게 될 것이다.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc26850d",
   "metadata": {},
   "source": [
    "**(2)** **알게된 점**\n",
    "<br>\n",
    "<br>\n",
    "- 정규표현식의 기본적인 메타문자나 그룹핑에 대해 알게 되었다. ^, [], \\, - 등등 정규표현식의 메타문자는 내 프로젝트에서 사용할 일이 없다고 하더라도 다른 사람의 코드를 읽어내는데 필요한 지식이다. 또한, ()를 이용하여 정규표현식 내에서 그룹핑을 하게되면, ()안의 형식에 해당하는 문자를 텍스트에서 찾아내고, 이를 r'\\1'과 같이 호출하여 사용할 수도 있다. 정규표현식에서의 캡처와 연계되는 개념이므로, 앞으로 캡쳐에 대해 학습해 나갈 생각이다.\n",
    "<br>\n",
    "<br>\n",
    "- 앞서 어려웠던 점에서 설명했었던 것처럼 RNN 각 계층의 단순한 구조에 대해서 알게 되었다. 다시 짧게 설명해보자면, 이번 프로젝트에서 RNN 은 각각 Embedded layer, RNN layer, Linear layer 로 나누어진다. Embedded layer 는 입력된 데이터들을 추상화하는 역할을 수행하게 되며, RNN layer 는 입력된 데이터들을 읽어가며, 각 데이터들의 연관성을 분석해나간다. 마지막으로, linear layer 에서는 앞서 분석한 연관성을 기반으로 새로운 단어들을 예측하여 생성하게 된다. 다른 계층의 이름이나, 역할, 원리 등에 대해서는 차차 학습해나가보기로 한다.\n",
    "<br>\n",
    "<br>\n",
    "- 정제된 각 문장들을 토큰화하고, 텐서로 변환해주는 과정을 구현해보았다. 실제로 컴퓨터에 각 문장들을 그대로 입력하게 되면, 컴퓨터는 이를 읽어낼 수 없다. 각 문장은 단어들로 토큰화되어 각각의 인덱스를 가지고 단어장에 등록되어야 하며, 문장들은 다시 인덱스에 맞게 숫자로 변환되어 표현되어야 한다. 이렇게 한 문장을 단어로 구분하여 각 단어의 인덱스로 표현한 형태를 tensor 라고 한다. 스칼라, 벡터처럼 tensor 는 수치값의 나열이며, 이번 프로젝트에서는 문장을 표현한다. 또한, 이렇게 tensor 로 변환된 각각의 문장들은 서로의 길이를 맞춰주어야 한다. 이는 이후에 있을 연산들을 위해 수행하는 작업으로 사료된다. 이 때, 짧은 길이의 문장들은 그 tensor 의 길이도 짧기 때문에, max_len의 길이에 맞춰 padding을 추가로 할당받는다.\n",
    "<br>\n",
    "<br>\n",
    "- 이외에 모델에 넣을 데이터를 batch 단위로 나누어주는 작업을 수행하기도 했다. 10만개가 넘어가는 모든 문장들을 한 번에 model 에 넣게 되면, 속도와 성능에 영향을 미치게 될 것이다. 따라서, 모델에 한 번에 넣게 될 데이터의 사이즈를 batch_size 로 나누어주고 1 EPOCH 의 1 step 마다 1 batch 를 넣어 모델을 학습시키게 된다. 이렇게 각 batch 가 모두 학습되어 전체 데이터에 대한 학습이 1회 끝나면, 이를 1 EPOCH 라 한다. 이 때, 전체 데이터가 각 batch 에 할당된 데이터의 수로 나누어 떨어지지 않을 경우에는 drop-remainder 옵션을 활용하여, 남은 데이터들을 drop 할 것인지 따로 모아 하나의 batch 로 할당할 것인지를 선택할 수 있다.\n",
    "<br>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13ba3cab",
   "metadata": {},
   "source": [
    "**(3)** **모호한 점**\n",
    "<br>\n",
    "<br>\n",
    "- 프로젝트의 난이도가 상당히 어렵게 느껴졌던 만큼, 감이 잡히지 않는 부분이 많았다. 예를 들면, '\\<start>'와 '\\<end>'가 그러했다. 정제된 문장 전체를 x_data 와 y_data, 즉 입력 데이터와 label로 나누어 줄 때, 입력 데이터의 앞에는 '\\<start>' 가 붙고 '\\<end>' 를 제거해주었으며, 반대로 label 데이터에 대해서는 '\\<end>' 를 마지막에 붙이고, 문장의 앞에서 '\\<start>' 를 제거해주었다. 입력 데이터의 형식과 label 데이터의 형식이 가지는 이러한 차이가 모델의 학습 및 문장 생성 과정에서 어떠한 의미를 가지는지 더 학습하여야한다.\n",
    "<br>\n",
    "<br>\n",
    "- 이외에 정규표현식에 관해서도 추가적인 학습이 필요할 것이다. 지금까지는 프로젝트를 진행하면서 사용할 일이 없어 학습하지 않았지만, 앞으로 머신러닝 및 인공지능과 관련한 다른 사람의 코드를 접하게 될 때, 용이하게 그 코드를 해석할 수 있기 위해서는 정규표현식에 대한 학습이 필요할 것이다.\n",
    "<br>\n",
    "<br>\n",
    "- 처음 접해본 순환신경망에 대해 학습해나갈 계획이다. 합성곱에 이어 이번에 접한 순환신경망은 그 구조와 원리에 대해 합성곱만큼 알지 못하기 때문에 더욱 어려웠다. 심지어 합성곱을 활용한 이미지 분류기는 설계 중 사진을 확인할 수 있어 직관적으로 진행을 파악할 수 있지만, 텍스트를 활용한 순환신경망 모델이었다보니, 해당 부분에 대해 이해가 더욱 어려웠던 것 같다. 순환신경망의 각 계층과 계층의 역할에 대해 앞으로 자세히 학습해나갈 예정이다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
